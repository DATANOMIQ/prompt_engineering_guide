{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b39920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports and environment setup\n",
    "import openai\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict, Any, Optional\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class PromptEngineering:\n",
    "    \"\"\"\n",
    "    Main class for demonstrating prompt engineering concepts\n",
    "    \"\"\"\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\", temperature=0.7, max_tokens=256):\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def set_parameters(self, model=None, temperature=None, max_tokens=None, \n",
    "                      top_p=1, frequency_penalty=0, presence_penalty=0):\n",
    "        \"\"\"Configure OpenAI parameters for different demonstrations\"\"\"\n",
    "        params = {\n",
    "            'model': model or self.model,\n",
    "            'temperature': temperature if temperature is not None else self.temperature,\n",
    "            'max_tokens': max_tokens or self.max_tokens,\n",
    "            'top_p': top_p,\n",
    "            'frequency_penalty': frequency_penalty,\n",
    "            'presence_penalty': presence_penalty\n",
    "        }\n",
    "        return params\n",
    "    \n",
    "    def get_completion(self, messages, **kwargs):\n",
    "        \"\"\"Get completion from OpenAI API with error handling\"\"\"\n",
    "        params = self.set_parameters(**kwargs)\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=params['model'],\n",
    "                messages=messages,\n",
    "                temperature=params['temperature'],\n",
    "                max_tokens=params['max_tokens'],\n",
    "                top_p=params['top_p'],\n",
    "                frequency_penalty=params['frequency_penalty'],\n",
    "                presence_penalty=params['presence_penalty']\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def display_result(self, prompt, response, concept=\"Basic Prompting\"):\n",
    "        \"\"\"Display results in a formatted way for workshop demonstrations\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CONCEPT: {concept}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"PROMPT:\\n{prompt}\")\n",
    "        print(f\"\\nRESPONSE:\\n{response}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Initialize the main demonstration class\n",
    "pe_demo = PromptEngineering()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_material",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
